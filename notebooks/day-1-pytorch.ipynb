{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Mastering PyTorch By Ashish Ranjan Jha\nWe used the following tutorial to guide our hands-on session as well:\n- [Deep Learning with PyTorch: A 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)","metadata":{"_uuid":"b52f5c57-7d76-436b-a467-70109fae6982","_cell_guid":"b6662a82-127e-4398-bf8c-f339259bd3b0","trusted":true}},{"cell_type":"markdown","source":"## Chapter 1 - Overview of Deep Learning Using PyTorch","metadata":{"_uuid":"976834ef-d744-45d4-a406-f769b2f94053","_cell_guid":"45668e7e-6cbf-4684-9eac-3f319ba0a54b","trusted":true}},{"cell_type":"markdown","source":"Deep Learning is a class of machine learning methods that has revolutionized the way computers/machines are used to build automated solutions for real-life problems in a way that wasn't possible before. Deep Learning uses large amounts of data to learn non-trival relationships between inputs and outputs in the form of complex nonlinear functions.\n\nSome of the inputs and outputs could be:\n•Input: An image of a text; output: Text\n•Input: Text; output: A natural voice speaking the text\n•Input: A natural voice speaking the text; output: Transcribed text\nAnd so on. (The above examples deliberately exclude tabular input data because gradient boosted trees (XGBoost, LightGBM, CatBoost) still outperform deep learning on such data.)","metadata":{"_uuid":"bb154820-fbc1-4755-90db-653cb89c602e","_cell_guid":"d3707a92-d458-4dd1-bf07-536a03d1fb49","trusted":true}},{"cell_type":"markdown","source":"Some of the well-known layers are the following:\n\n• Fully-connected or linear: In a fully connected layer, all neurons preceding this layer are connected to all neurons succeeding this layer. Fully connected layers are a fundamental unit of many – in fact, most – deep learning classifiers.\n\n• Convolutional: In convolutional layer, where a convolutional kernel (or filter) is convolved over the input. Convolutional layers are a fundamental unit of Convolutional Neural Networks (CNNs), which are the most effective models for solving computer vision problems.\n\n• Recurrent: Recurrent layers have an advantage over fully connected layers in that they exhibit memorizing capabilities, which comes in handy working with sequential data where one needs to remember past inputs along with the present inputs.\n\n• DeConv (the reverse of a convolutional layer): Quite the opposite of a convolutional layer, a DeConvolutional Layer works by expanding the input data spatially and hence is crucial in models that aim to generate or reconstruct images, for example.","metadata":{"_uuid":"33c601ca-f46f-4205-8923-97eb7ea71e3a","_cell_guid":"4714ee32-b4a0-403e-a3f3-09199c9d6071","trusted":true}},{"cell_type":"markdown","source":"### PyTorch modules","metadata":{"_uuid":"130d1c31-7a99-4648-ab93-601db6e1469f","_cell_guid":"969056e9-dd6c-44ef-880b-5ad5825bdc83","trusted":true}},{"cell_type":"markdown","source":"The PyTorch library, besides offering the computational functions as NumPy does, also offers a set of\nmodules that enable developers to quickly design, train, and test deep learning models. The following\nare some of the most useful modules.","metadata":{"_uuid":"7e8c1a33-e17a-4ac7-8c1d-d61bab2b6a86","_cell_guid":"e600a349-7865-41a3-9d47-e67cd4588917","execution":{"iopub.status.busy":"2024-08-18T06:38:51.464564Z","iopub.execute_input":"2024-08-18T06:38:51.465308Z","iopub.status.idle":"2024-08-18T06:38:51.476855Z","shell.execute_reply.started":"2024-08-18T06:38:51.465275Z","shell.execute_reply":"2024-08-18T06:38:51.475450Z"},"trusted":true}},{"cell_type":"markdown","source":"#### torch.autograd","metadata":{"_uuid":"dd9a08f9-37a8-4778-9030-f8f77a62623f","_cell_guid":"53bb77de-ccd6-49be-8655-08e6b1d1a070","trusted":true}},{"cell_type":"markdown","source":"`torch.autograd` is PyTorch’s automatic differentiation engine that powers neural network training. \n\nNeural networks (NNs) are like a series of linked functions that process input data. These functions have parameters (weights and biases) that are kept in tensors in PyTorch.\n\nTraining a neural network involves two main steps:\n\n**Forward Propagation**\nIn this step, the neural network makes an educated guess about the output. It does this by passing the input data through its functions to produce a prediction.\n\n**Backward Propagation**\nHere, the neural network learns from its mistakes. It adjusts its parameters based on the difference between its prediction and the actual result. The network works backwards from the output, calculates how much each parameter contributed to the error (using derivatives called gradients), and updates the parameters to improve the prediction. This process of updating is done using a method called gradient descent.","metadata":{"_uuid":"70726000-bc81-4fe7-80f0-216ee6a9b006","_cell_guid":"fc438bd6-b90b-4c93-9e69-6091547da9a5","jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"# Let's take a look at a single training step. \n\n# Import dependencies \nimport torch\nfrom torchvision.models import resnet18, ResNet18_Weights\n\nmodel = resnet18(weights=ResNet18_Weights.DEFAULT)\ndata = torch.rand(1,3,64,64)\nlabels = torch.rand(1, 1000)\n\n# forward pass \nprediction = model(data)\n\n# calculate the loss\nloss = (prediction - labels).sum()\n\n# backward pass\nloss.backward()\n\n# load an optimizer \noptim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n\n# gradient descent\noptim.step()","metadata":{"_uuid":"b24881ab-979a-453d-a2f7-edb9dae49157","_cell_guid":"6ccc6a2b-417a-45b4-bbaa-1e1fc18d49f0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-18T10:15:39.556449Z","iopub.execute_input":"2024-08-18T10:15:39.557351Z","iopub.status.idle":"2024-08-18T10:15:45.065285Z","shell.execute_reply.started":"2024-08-18T10:15:39.557314Z","shell.execute_reply":"2024-08-18T10:15:45.064376Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 150MB/s] \n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### torch.nn\nWhen building a neural network architecture, the fundamental aspects that the network is built on are the number of layers, the number of neurons in each layer, and which of those are learnable, and so on. \n\nThe PyTorch nn module enables users to quickly instantiate neural network architectures by defining some of these high-level aspects as opposed to having to specify all the details manually.","metadata":{"_uuid":"78d834f4-43ff-43b8-b415-f35a01f02b60","_cell_guid":"f72f4071-21d9-4723-a8ce-ecf6a374bfc4","trusted":true}},{"cell_type":"code","source":"import math\nimport torch\n'''\nLet's assume a 64 dimensional input and a 4-dimensional output for this 1-layer network. Hence, we initialize a 64x4 dimensional matrix filled with random values.\n'''\nweights = torch.randn(64, 4)/math.sqrt(64)\n'''\nWe then ensure that the parameters of this neural network are trainable, i.e., the numbers in the 64x4 matrix can be tuned with the help of backpropagation of gradients.\n'''\nweights.requires_grad_()\n'''finally we also add the bias weights for the 4-dimensional output, and make these trainable too'''\nbias = torch.zeros(4,requires_grad=True)","metadata":{"_uuid":"c7ba1bc4-5cfb-4484-8c17-eeb3a0b5fc94","_cell_guid":"5e5e38c2-fe23-4d53-a38e-d1d66f6e8847","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-18T10:15:45.066994Z","iopub.execute_input":"2024-08-18T10:15:45.067699Z","iopub.status.idle":"2024-08-18T10:15:45.075451Z","shell.execute_reply.started":"2024-08-18T10:15:45.067664Z","shell.execute_reply":"2024-08-18T10:15:45.074622Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"We can instead use nn.Linear(64, 4) to represent the same thing in PyTorch. In TensorFlow, this could be written as tf.keras.layers.Dense(64, input_shape=(4,), activation=None).","metadata":{"_uuid":"200daa0d-68fc-4a7b-8273-ddb069f5498c","_cell_guid":"4b58aee2-beea-4fb9-a4f0-d9390008dca7","trusted":true}},{"cell_type":"code","source":"# if you are thinking about how 64 dimensional input look like ?\n'''\nA 64-dimensional input typically refers to a data point represented as a vector with 64 elements. Each element can be a feature, a measurement, or a value that represents some aspect of the data.\n'''\nx = torch.randn(64)\nprint(x)\n\ny = torch.randn(64,4)\nprint(y)\n\n# see the difference between x and y here.","metadata":{"_uuid":"d652c519-c624-4704-b732-bdd3afb941a8","_cell_guid":"b6343029-3400-42eb-95d0-31277ef48da8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-18T10:15:50.553599Z","iopub.execute_input":"2024-08-18T10:15:50.554448Z","iopub.status.idle":"2024-08-18T10:15:50.581712Z","shell.execute_reply.started":"2024-08-18T10:15:50.554413Z","shell.execute_reply":"2024-08-18T10:15:50.580611Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"tensor([-0.2963,  1.3469, -0.7804,  1.1162, -0.2191, -1.3136, -0.7041,  0.4698,\n        -0.8653,  0.8924,  0.4866, -1.0979, -0.6410,  0.2095, -0.2444, -0.3963,\n         0.1754, -0.2154,  0.2450,  0.4057,  0.4755, -1.1892,  1.6432,  0.2591,\n        -0.2277,  0.0310,  0.8761,  2.2952,  0.5770,  0.5841, -0.7167,  0.2036,\n         0.2739, -1.7121, -0.7243,  0.0449, -1.2325, -0.9400, -0.6814,  2.2289,\n         1.2043, -0.3879,  1.6313,  0.2762, -1.0367, -0.9182,  0.1398, -0.1379,\n        -1.0946, -0.1464, -0.1394, -1.5116, -0.3661,  1.8563,  0.4153, -0.6331,\n        -1.0518,  0.6365,  1.0537,  0.5225, -0.9475, -0.4695,  1.1794,  1.5329])\ntensor([[-0.7816,  0.1137, -1.2018, -0.0897],\n        [ 0.1645,  0.9752,  2.8006,  1.0079],\n        [-1.6533,  0.8117, -0.2668,  1.0208],\n        [-2.2112, -0.6038, -0.0998, -0.9875],\n        [ 0.9569, -0.9595, -1.5058,  0.4872],\n        [ 0.5487,  1.1966, -0.5981,  1.6318],\n        [ 0.3414,  2.1036, -0.5699, -1.0466],\n        [ 0.4907, -0.5955,  0.7983, -0.0425],\n        [ 1.2173,  0.8469,  0.2216,  1.4103],\n        [ 1.0555, -0.7035,  1.5362, -0.3154],\n        [-0.6549,  1.0328,  1.2377, -1.1662],\n        [ 0.8736, -0.6641,  0.5243, -0.5590],\n        [-0.3122,  0.3951,  0.4962, -1.0931],\n        [ 1.0802,  0.5925, -0.2590, -0.6886],\n        [-1.4263,  0.3578,  0.2063, -0.6498],\n        [-1.0970,  2.0104, -1.5238, -0.7410],\n        [-1.1704, -2.0730, -1.6045,  0.1206],\n        [-0.3057,  1.0105,  0.6103,  2.4650],\n        [ 1.3303,  1.7207,  0.1525,  0.9327],\n        [-1.7226, -0.0593, -0.3690, -2.4834],\n        [-1.6104,  1.0243,  0.0851, -0.9717],\n        [-1.9501, -0.6037,  0.4455,  1.6247],\n        [-0.6091,  0.5394,  1.5057, -0.1963],\n        [-0.8747,  0.6620,  1.9531,  0.6277],\n        [ 1.0686, -1.0394, -0.2033, -1.1090],\n        [ 1.7511,  0.7444, -0.5746,  0.0930],\n        [ 0.3701,  1.3466,  0.8525, -0.8681],\n        [-0.9506,  0.1753,  1.1029,  0.3934],\n        [ 0.4201, -0.9001,  0.8778, -0.1306],\n        [-0.3025,  1.2707,  0.9196, -0.7208],\n        [-0.6600, -0.3154, -0.2889, -0.3593],\n        [ 0.6089, -0.2413,  1.1116,  0.5713],\n        [ 2.7137, -0.8304,  0.5792, -1.1276],\n        [ 0.6089, -2.0326, -0.2939,  0.6188],\n        [ 1.4069, -0.0268, -0.2481, -0.4927],\n        [ 0.0765,  0.5447,  1.0076, -1.3524],\n        [ 1.9868,  0.1239, -0.8128,  1.8707],\n        [ 0.6943, -0.3427,  0.6099,  1.4879],\n        [-2.0749,  0.1616,  0.3454,  1.7194],\n        [-0.2999, -0.4360,  1.7522, -0.3597],\n        [-0.6409, -1.4901,  0.0543,  0.9807],\n        [ 0.2479,  1.7736, -0.6173, -2.8270],\n        [-1.6919, -0.0820,  0.6933,  0.0915],\n        [ 0.1535, -0.2162,  0.6872, -0.6549],\n        [ 0.1144, -0.1957,  0.8225, -0.8825],\n        [-0.2517, -1.3477, -0.7246,  0.0982],\n        [ 1.6175,  0.0287,  0.3647, -0.4446],\n        [ 0.3985,  0.0305,  0.3196, -3.0694],\n        [-0.5003,  0.4072, -1.4681,  1.2575],\n        [-1.3854, -0.1238, -0.1957,  0.3916],\n        [-0.7205, -0.3215,  0.1965, -1.6795],\n        [-2.1088,  2.4992,  1.2842, -1.8211],\n        [ 1.0998,  0.2311,  0.4149,  0.3738],\n        [-0.3940, -1.7698, -1.6242,  0.1484],\n        [ 0.3187, -1.5728, -0.3369, -0.3351],\n        [-0.4109, -0.8647, -0.2945,  0.9114],\n        [-0.6669,  1.0567,  0.2685, -0.5002],\n        [ 1.2404, -0.8383, -0.2788, -0.9969],\n        [-0.0250,  0.0728,  0.3547,  1.6243],\n        [-0.7910, -0.6111,  0.7576,  1.6647],\n        [-0.8539,  0.3431,  0.2119, -0.1208],\n        [ 0.2276, -2.0294,  0.6021, -0.6258],\n        [-1.6829,  0.1815, -0.7156, -2.4396],\n        [ 0.7589, -1.5491,  0.7194,  1.8933]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Differences:**\n\n1. Shape and Dimensions:\nx: This tensor is a 1-dimensional tensor (vector) with 64 elements.\ny: This tensor is a 2-dimensional tensor (matrix) with 64 rows and 4 columns.\n\n2. Structure:\nx: A simple list of 64 random values drawn from a standard normal distribution (mean = 0, standard deviation = 1).\ny: A matrix with 64 rows and 4 columns, where each element is a random value drawn from a standard normal distribution.\n\n3. Usage:\nx: Typically used as a single data point with 64 features. This could be useful in various applications like a feature vector in machine learning.\ny: Typically used as a batch of data points, where each row represents a data point with 4 features. This is useful in scenarios like feeding data into a neural network in mini-batches.","metadata":{"_uuid":"fb87d6d2-69d2-4eb1-bbeb-7b54725a4541","_cell_guid":"6ed6b09f-4389-452b-8387-00bf500b924c","trusted":true}},{"cell_type":"markdown","source":"Within the torch.nn module, there is a submodule called **torch.nn.functional**. This submodule\nconsists of all the functions within the torch.nn module, whereas all the other submodules are classes.\nThese functions are loss functions, activating functions, and also neural functions that can be used\nto create neural networks in a functional manner (that is, when each subsequent layer is expressed\nas a function of the previous layer) such as pooling, convolutional, and linear functions.","metadata":{"_uuid":"00fc09d1-1fd3-49c4-881f-b980c36733ab","_cell_guid":"ec34b157-7b95-420a-ab40-13339a0b3668","trusted":true}},{"cell_type":"code","source":"# Example (error add we have not defined model which we will later.)\nimport torch.nn.functional as F\nloss_func = F.binary_cross_entropy\nloss = loss_func(model(X), y)","metadata":{"_uuid":"f0d36cf8-bb53-4073-8d97-acfeb0fa7c17","_cell_guid":"4c86cd7e-70bf-4090-9794-70d23ce7e55c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-18T10:15:54.526374Z","iopub.execute_input":"2024-08-18T10:15:54.527209Z","iopub.status.idle":"2024-08-18T10:15:54.921391Z","shell.execute_reply.started":"2024-08-18T10:15:54.527175Z","shell.execute_reply":"2024-08-18T10:15:54.920165Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      3\u001b[0m loss_func \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy\n\u001b[0;32m----> 4\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(model(\u001b[43mX\u001b[49m), y)\n","\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"],"ename":"NameError","evalue":"name 'X' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"### Training a neural network using PyTorch","metadata":{"_uuid":"0e8f7e4c-e792-4827-9cbd-2579973cbfd8","_cell_guid":"20e96337-678b-4ff0-b07d-22ee7ac8b6e9","trusted":true}},{"cell_type":"markdown","source":"A typical training procedure for a neural network is as follows:\n\n- Define the neural network that has some learnable parameters (or weights)\n\n- Iterate over a dataset of inputs\n\n- Process input through the network\n\n- Compute the loss (how far is the output from being correct)\n\n- Propagate gradients back into the network’s parameters\n\n- Update the weights of the network, typically using a simple update rule: `weight = weight - learning_rate * gradient`","metadata":{"_uuid":"14167404-6654-4c21-9765-fabc0c3ec843","_cell_guid":"74ec2528-ed9e-4d18-8c9e-5ac6a5389372","trusted":true}},{"cell_type":"markdown","source":"![architecture](https://pytorch.org/tutorials/_images/mnist.png)","metadata":{"_uuid":"bb1013f2-ec9b-49ed-b9ec-d16ff1981967","_cell_guid":"32ee606f-78ea-459d-a21a-3231a3d4acdb","trusted":true}},{"cell_type":"markdown","source":"It is a simple feed-forward network. It takes the input, feeds it through several layers one after the other, and then finally gives the output.","metadata":{"_uuid":"9030af82-49d4-44d1-b892-17e0c85abc90","_cell_guid":"18182e3b-225b-4050-8ca4-083a4ae831a0","trusted":true}},{"cell_type":"markdown","source":"#### Network Breakdown:\n**Input Layer (32x32)** \n\nThe input to the network is a 32x32 pixel grayscale image. The image in the diagram appears to be a handwritten letter \"A,\" but typically, LeNet-5 was used on the MNIST dataset, which contains 28x28 pixel images of handwritten digits. The images are zero-padded to 32x32. (Information from reference; now let's break down the architecture based on this image only)\n\n**C1: First Convolutional Layer**\n\n- Feature Maps: 6 ; \nThe image shows \"C1: feature maps 6@28x28,\" which tells you that the first convolutional layer (C1) generates 6 feature maps.\n\n- Kernel Size: 5x5 ; \nAlthough the kernel size is not explicitly mentioned in the image, you can infer it based on the input size and the output size of the convolutional layer. The input is 32x32, and after applying the convolution, the output is 28x28. Given the formula for the output size of a convolution:\n\n`Output Size = Input Size − Kernel Size + 1`\n`Kernel Size = Input Size− Output Size + 1`\n\nSubstituting the values:\n\n`Kernel Size = 32 − 28 + 1 = 5`\n\nSo, the kernel size is 5x5.\n\n- Output Size: 28x28 ;\nThe image directly labels the output size of the first convolutional layer as 28x28, which you can see under \"C1: feature maps 6@28x28.\"\n\n**S2: First Subsampling (Pooling) Layer**\n\n- Feature Maps: 6\n- Subsampling Method: Typically, average pooling with a stride of 2\n- Output Size: 14x14\n\n\nCalculation:\nThe output size of a pooling layer can be calculated using the formula:\n\n`Output Size = (Input Size − Pool Size)/Stride + 1`\n\nFor simplicity, in most standard implementations of LeNet-5:\n\nPool Size: Typically 2x2\nStride: Typically 2\n\n`Output Size = (28 − 2)/2 + 1 = 14`\n\n**Similarly**\n**C3: Second Convolutional Layer**\n- Feature Maps: 16\n- Kernel Size: 5x5\n- Output Size: 10x10\n\n**S4: Second Subsampling (Pooling) Layer**\n- Feature Maps: 16\n- Subsampling Method: Average pooling with a stride of 2\n- Output Size: 5x5\n\n**C5: Fully Connected Convolutional Layer**\n-> Here, a fully connected layer (also known as a dense layer) takes the flattened output from the previous layer as input. If you have 400 (16x(5x5)) inputs (from the previous layer), and the fully connected layer has 120 neurons, each neuron will receive inputs from all 400 features.\n- Neurons: 120\n- Kernel Size: 5x5\n\n**F6: Fully Connected Layer**\n- Neurons: 84\n\n**Output Layer**\n- Neurons: 10","metadata":{"_uuid":"f0a8b85c-c435-4307-b8db-0b4f9de9b149","_cell_guid":"089bdc65-2e12-45b2-b5bb-12526f27c330","trusted":true}},{"cell_type":"code","source":"# Import dependencies\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"_uuid":"b4a04a9f-1954-45ff-9e04-676683cd3d80","_cell_guid":"bf08c53b-ec4c-4f54-8a2b-0bb7b934f954","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-18T10:15:59.839205Z","iopub.execute_input":"2024-08-18T10:15:59.839666Z","iopub.status.idle":"2024-08-18T10:15:59.844790Z","shell.execute_reply.started":"2024-08-18T10:15:59.839634Z","shell.execute_reply":"2024-08-18T10:15:59.843710Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # 1 input image channel, 6 output channels, 5x5 square convolution\n        self.cn1 = nn.Conv2d(1, 6, 5)\n        self.cn2 = nn.Conv2d(6, 16, 5)\n        \n        # an affine operation: y = Wx + b\n        self.fc1 = nn.Linear(16*5*5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n        \n    def forward(self,input):\n        # it uses RELU activation function, and\n        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n        c1 = F.relu(self.cn1(input))\n        \n        # this layer does not have any parameter, and outputs a (N, 6, 14, 14) Tensor\n        s2 = F.max_pool2d(c1, (2, 2))\n        \n        # it uses RELU activation function, and\n        # outputs a (N, 16, 10, 10) Tensor\n        c3 = F.relu(self.cn2(s2))\n        \n        # Subsampling layer S4: 2x2 grid, purely functional,\n        # this layer does not have any parameter, and outputs a (N, 16, 5, 5) Tensor\n        s4 = F.max_pool2d(c3, 2)\n        \n        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n        s4 = torch.flatten(s4, 1)\n        \n        # Fully connected layer F5: (N, 400) Tensor input,\n        # and outputs a (N, 120) Tensor, it uses RELU activation function\n        f5 = F.relu(self.fc1(s4))\n        \n        # Fully connected layer F6: (N, 120) Tensor input,\n        # and outputs a (N, 84) Tensor, it uses RELU activation function\n        f6 = F.relu(self.fc2(f5))\n        \n        # Gaussian layer OUTPUT: (N, 84) Tensor input, and\n        # outputs a (N, 10) Tensor\n        output = self.fc3(f6)\n        return output\n    \nnet = Net()\nprint(net)","metadata":{"_uuid":"0f00e836-be45-4393-b917-67707ffd41b2","_cell_guid":"fa5aa17c-6fbf-4513-aeb6-4c21b4a38067","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-18T10:16:00.045658Z","iopub.execute_input":"2024-08-18T10:16:00.046157Z","iopub.status.idle":"2024-08-18T10:16:00.058294Z","shell.execute_reply.started":"2024-08-18T10:16:00.046128Z","shell.execute_reply":"2024-08-18T10:16:00.057407Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Net(\n  (cn1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (cn2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The forward function, and the backward function (where gradients are computed) is automatically defined using autograd. We can use any of the Tensor operations in the forward function.\n\nThe learnable parameters of a model are returned by `net.parameters()`","metadata":{"_uuid":"ebcf6dd7-43c7-4b33-82f3-17eff389680e","_cell_guid":"1e5f827f-aea9-474d-b344-10d7b655ecb2","trusted":true}},{"cell_type":"code","source":"params = list(net.parameters())\nprint(len(params))\nprint(params[0].size()) # cn1's weight","metadata":{"_uuid":"666525cf-7dfd-4b97-8071-488524b60812","_cell_guid":"4de93a80-7a19-4775-94eb-1c2f744c5251","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-18T10:16:02.091712Z","iopub.execute_input":"2024-08-18T10:16:02.092066Z","iopub.status.idle":"2024-08-18T10:16:02.097646Z","shell.execute_reply.started":"2024-08-18T10:16:02.092038Z","shell.execute_reply":"2024-08-18T10:16:02.096550Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"10\ntorch.Size([6, 1, 5, 5])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We need to resize the inputs if input size is not 32x32 as expected input size of this net(LeNet) is 32x32.","metadata":{"_uuid":"0a7ac2f7-4e9f-48c7-a59b-dcb0b70f105a","_cell_guid":"ede1fb22-5328-43d0-ab21-124d7ad2eef9","trusted":true}},{"cell_type":"code","source":"# Let's try some random 32x32 input.\ninput = torch.randn(1,1,32,32) # (batch_size, no_of_channels, height, width)\nout = net(input)\nprint(out)","metadata":{"_uuid":"3f5fdcbf-ea4c-4b19-a346-889cb8d547e5","_cell_guid":"71b53b84-4b4a-4cf6-893a-98865e8ac74e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-18T10:16:03.234167Z","iopub.execute_input":"2024-08-18T10:16:03.234879Z","iopub.status.idle":"2024-08-18T10:16:03.245722Z","shell.execute_reply.started":"2024-08-18T10:16:03.234844Z","shell.execute_reply":"2024-08-18T10:16:03.244751Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"tensor([[-0.0311, -0.0800, -0.0268,  0.0915, -0.0534,  0.0446, -0.0026,  0.0173,\n         -0.0836,  0.0089]], grad_fn=<AddmmBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"_uuid":"491b8b98-2d3a-482d-bf6e-ab5bbf916d18","_cell_guid":"a34192f1-7bd3-419c-b145-497e520a88cb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}