{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Mastering PyTorch Ashish Ranjan Jha","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Deep CNN Architectures","metadata":{}},{"cell_type":"markdown","source":"### Why are CNNs so powerful?\nCNNs are among the most powerful machine learning models at solving challenging problems such as image classification, object detection, object segmentation, video processing, natural language pro-cessing, and speech recognition.\n\nFew reasons:\n- Weight sharing: Different features are extracted using the same set of weights or parameters. This makes CNNs parameter-efficient.\n- Automatic feature extraction: Multiple feature extraction stages help a CNN to atutomatically learn feature representation in a dataset. \n- Hierarchical learning: The multi-layered CNN structure helps CNNs to learn low-, mid-, and high-level features.\n- The ability to explore both spatial and temporal correlations in the data, such as in video-processing tasks.\n\nBesides these pre-existing fundamental characteristics, CNNs have advanced over the years with the help of improvements in the following areas:\n- The use of better activation and loss functions, such as using ReLU to overcome the vanishing gradient problem.\n- Parameter optimization, such as using an optimizer based on Adaptive Momentum (Adam) instead of simple stochastic gradient descent.\n- Regularization: Applying dropouts and batch normalization besides L2 regularization.\n\n**NOTE: Features** are the high-level representations of input data that the model generates with its parameters.","metadata":{}},{"cell_type":"markdown","source":"The various architectural innovations:\n- Spatial exploration-based CNNs: The idea behind spatial exploration is using different kernel sizes in order to explore different levels of visual features in input data.\n- Depth-based CNNs: The depth here refers to the depth of the neural network, that is, the number of layers. So, the idea here is to create a CNN model with multiple convolutional layers in order to extract highly complex visual features.\n- Width-based CNNs: Width refers to the number of channels or feature maps in the data or features extracted from the data. So, width-based CNNs are all about increasing the number of feature maps as we go from the input to the output layers.\n- Multi-path-based CNNs: So far, the preceding three types of architectures have had monotonicity in connections between layers; that is, direct connections exist only between consecutive layers. Multi-path CNNs brought the idea of making shortcut connections or skip connections between non-consecutive layers.","metadata":{}},{"cell_type":"markdown","source":"### Fine-tuning the AlexNet model","metadata":{}},{"cell_type":"markdown","source":"![AlexNet](https://neurohive.io/wp-content/uploads/2018/10/AlexNet-1.png)","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass AlexNet(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(AlexNet, self).__init__()\n        self.feats = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0),  # Adjusted out_channels and padding\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),  \n            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),  # Adjusted out_channels\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),  \n            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),  # Adjusted out_channels\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),  # Adjusted out_channels\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),  # Adjusted out_channels\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),  \n        )\n        self.clf = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, inp):\n        op = self.feats(inp)\n        op = torch.flatten(op, 1)\n        op = self.clf(op)\n        return op\n","metadata":{"execution":{"iopub.status.busy":"2024-08-19T16:12:15.494148Z","iopub.execute_input":"2024-08-19T16:12:15.495362Z","iopub.status.idle":"2024-08-19T16:12:15.508021Z","shell.execute_reply.started":"2024-08-19T16:12:15.495308Z","shell.execute_reply":"2024-08-19T16:12:15.506468Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"But besides the option of initializing the model architecture and training it ourselves, PyTorch, with its torchvision package, provides a models sub-package, which contains definitions of CNN models meant for solving different tasks, such as image classification, semantic segmentation, object detection, and so on.\n\n- AlexNet\n- VGG\n- ResNet\n- SqueezeNet\n- DenseNet\n- Inception v3\n- GoogLeNet\n- ShuffleNet v2\n- MobileNet v2\n- ResNeXt\n- Wide ResNet\n- MnasNet\n- EfficientNet","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}